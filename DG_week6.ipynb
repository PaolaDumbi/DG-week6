{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "e8qbRzsJtZcb"
      },
      "source": [
        "## Loading the file\n",
        "\n",
        "##### Tried to load the file with ray and modin but the process didn't work due to low memory \n",
        "##### File successfully loaded with pandas\n",
        "\n",
        "\n",
        "### link to the file used for assignement: https://drive.google.com/file/d/1vBFe9U4yBcO4QyyfDk8zt786Vn_XihrH/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ex4x-aaerL3y"
      },
      "outputs": [],
      "source": [
        "# Load the file with Ray\n",
        "# !pip install ray\n",
        "\n",
        "import ray\n",
        "\n",
        "ray.init() \n",
        "\n",
        "@ray.remote\n",
        "def read_file(file_path, num_lines):\n",
        "    with open(file_path, 'r') as file:\n",
        "        lines = file.readlines()[:num_lines]\n",
        "    return lines\n",
        "\n",
        "file_path = '/content/drive/MyDrive/yelp-dataset/yelp_review.csv'  \n",
        "num_lines = 30  \n",
        "\n",
        "lines = ray.get(read_file.remote(file_path, num_lines)) \n",
        "\n",
        "# Print the lines\n",
        "for line in lines:\n",
        "    print(line)\n",
        "\n",
        "ray.shutdown()  # Shutdown Ray\n",
        "\n",
        "# task was killed due to low memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3_5hIBeZRgY"
      },
      "outputs": [],
      "source": [
        "# !pip install modin[all]\n",
        "\n",
        "# Loading the file using modin\n",
        "import modin.pandas as md\n",
        "\n",
        "modin_rv=md.read_csv(\"/content/drive/MyDrive/yelp-dataset/yelp_review.csv\")\n",
        "modin_rv1=modin_rv.head(30)\n",
        "modin_rv1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ZGqmTSs_UHO-"
      },
      "outputs": [],
      "source": [
        "#loading the file using pandas\n",
        "import pandas as pd\n",
        "separator = ','\n",
        "reviews= pd.read_csv(\"/content/drive/MyDrive/yelp-dataset/yelp_review.csv\",sep=separator)\n",
        "# execution time: 1m22"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xpfj0xcGWwr1"
      },
      "outputs": [],
      "source": [
        "reviews1=reviews.head(30)\n",
        "reviews1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3YY6shst_5C"
      },
      "source": [
        "##### Required Tasks below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "XRHh1Q2VNqZS"
      },
      "outputs": [],
      "source": [
        "# validation functions for data columns\n",
        "import yaml\n",
        "import logging\n",
        "import re\n",
        "\n",
        "def read_config_file(filepath):\n",
        "    with open(filepath, 'r') as stream:\n",
        "        try:\n",
        "            return yaml.safe_load(stream)\n",
        "        except yaml.YAMLError as exc:\n",
        "            logging.error(exc)\n",
        "\n",
        "def clean_column_names(df):\n",
        "    # Remove whitespace from column names\n",
        "    df.columns = df.columns.str.strip()\n",
        "    # Replace whitespace with underscores and convert to lowercase\n",
        "    df.columns = df.columns.str.replace(' ', '_', regex=True)\n",
        "    # Remove special characters and convert to lowercase\n",
        "    df.columns = df.columns.str.replace('[^\\w]', '', regex=True).str.lower()\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ya_6pmvSKxm",
        "outputId": "895c3373-0554-4c70-e9bf-ad4a4c9a5aa5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting file.yaml\n"
          ]
        }
      ],
      "source": [
        "# Writting a YAML file\n",
        "\n",
        "%%writefile file.yaml\n",
        "file_type: csv\n",
        "dataset_name: trial1\n",
        "file_name: test_data1\n",
        "table_name: yielp_r\n",
        "inbound_delimiter: \",\"\n",
        "outbound_delimiter: \"|\"\n",
        "skip_leading_rows: 1\n",
        "columns: \n",
        "    - review_id\n",
        "    - business_id\n",
        "    - stars\n",
        "    - text\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZuHL-04dMql"
      },
      "outputs": [],
      "source": [
        "#Running validations on data column names \n",
        "\n",
        "separator = ','  \n",
        "data_df = reviews1\n",
        "\n",
        "# load yaml and extract column names \n",
        "with open('file.yaml', 'r') as yaml_file:\n",
        "    schema = yaml.safe_load(yaml_file)\n",
        "    expected_columns = schema['columns']\n",
        "\n",
        "#  comparing data file and yaml file \n",
        "num_columns_data = len(data_df.columns)\n",
        "num_columns_expected = len(expected_columns)\n",
        "\n",
        "column_names_data = set(data_df.columns)\n",
        "column_names_expected = set(expected_columns)\n",
        "\n",
        "if num_columns_data != num_columns_expected or column_names_data != column_names_expected:\n",
        "    raise ValueError('Column validation failed. The data file does not match the expected schema.')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "xaDFaOUohsUp"
      },
      "outputs": [],
      "source": [
        "# write the file in gzipped format \n",
        "import gzip\n",
        "\n",
        "separator = ','\n",
        "data_df.to_csv('output_file.txt', sep=separator, index=False)\n",
        "\n",
        "with open('output_file.txt', 'rb') as file_in:\n",
        "    with gzip.open('output_file.txt.gz', 'wb') as file_out:\n",
        "        file_out.writelines(file_in)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuUObyDAl3MN",
        "outputId": "bd99518f-f3f1-4088-ffc4-008a378411a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Total Rows': 149, 'Total Columns': 1, 'File Size (Bytes)': 7171}\n"
          ]
        }
      ],
      "source": [
        "# creating a summary of the file \n",
        "import os\n",
        "\n",
        "def summarize_file(file_path, separator='|'):\n",
        "    # Count total number of rows\n",
        "    def count_rows(file_path):\n",
        "        with gzip.open(file_path, 'rt') as file:\n",
        "            total_rows = sum(1 for _ in file)\n",
        "        return total_rows\n",
        "\n",
        "    total_rows = count_rows(file_path)\n",
        "\n",
        "    # Count total number of columns\n",
        "    def count_columns(file_path, separator):\n",
        "        with gzip.open(file_path, 'rt') as file:\n",
        "            header = file.readline().rstrip()\n",
        "            total_columns = len(header.split(separator))\n",
        "        return total_columns\n",
        "\n",
        "    total_columns = count_columns(file_path, separator)\n",
        "\n",
        "    # Get file size\n",
        "    def get_file_size(file_path):\n",
        "        size_bytes = os.path.getsize(file_path)\n",
        "        \n",
        "        return size_bytes\n",
        "    size_bytes= get_file_size(file_path)\n",
        "\n",
        "    # Return the summary\n",
        "    summary = {\n",
        "        'Total Rows': total_rows,\n",
        "        'Total Columns': total_columns,\n",
        "        'File Size (Bytes)': size_bytes\n",
        "    }\n",
        "\n",
        "    return summary\n",
        "\n",
        "file_path = 'output_file.txt.gz'  # Specify the path to the gzipped file\n",
        "summary = summarize_file(file_path)\n",
        "print(summary)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
